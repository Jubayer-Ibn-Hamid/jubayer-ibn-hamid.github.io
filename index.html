<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Jubayer Ibn Hamid</title>
  
  <meta name="author" content="Jubayer Ibn Hamid">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <!-- <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>"> -->  
  <link rel="icon" href="./images/moonicon.png">
	<!-- <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>"> -->
</head>


<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <heading style="display:block; font-size:3em; margin-bottom: 10px;">Jubayer Ibn Hamid</heading>
              </p>
              <p> I am a researcher at <a href="https://ai.stanford.edu">Stanford Artificial Intelligence Laboratory (SAIL)</a> advised by <a href="https://ai.stanford.edu/~cbfinn/">Chelsea Finn</a>. I am pursuing a B.S in Mathematical Physics and M.S in Computer Science at Stanford University.
              <p style="text-align:center">
              <p>
                My research focuses on the intersection of machine learning, offline reinforcement learning and representation learning. I am also interested in pure mathematics such as abstract algebra, algebraic/differential topology/geometry.
              <p style="text-align: center">  
              <p>
                I was born and raised in the beautiful city of Dhaka, Bangladesh. I am a diehard fan of FC Barcelona.
              <p style="text-align: center">  
              <!-- <p>
                In my free time, I watch a lot of football - I am a diehard fan of FC Barcelona. I also watch a lot of F1 where I support Mercedes. Other than that, I like listening to music, reading and going on long walks.
              <p style="text-align: center">   -->
                <a href="data/CV.pdf">CV</a> &nbsp/&nbsp
                <a href = "https://scholar.google.co.uk/citations?user=3G2EbP4AAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <!-- <a href="https://github.com/Jubayer-Hamid">Github</a> &nbsp/&nbsp -->
                <a href="mailto:jubayer@stanford.edu">Email</a> &nbsp/&nbsp
                <a href="https://twitter.com/jubayer_hamid">Twitter</a> &nbsp &nbsp
              </p>
            </td>
            <td style="padding:2.5%;width:20%;max-width:20%">
              <a href="./images/cohojubayer.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="./images/cohojubayer.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading style="display:block; font-size:2em; margin-bottom: 10px;">Research</heading>
              <p>
                I am currently focused on two main areas: offline policy evaluation, specifically policies trained using behavioral cloning or offline RL, and test-time policy decoding methods, particularly in sampling more optimal strategies in a coherent manner.
              </p>
              <p>
                (*) denotes co-first authorship
              </p>
            
              <!-- <p>
              I am broadly interested in researching scalable methods for helping robots acquire complex behaviours through learning. To that end, I am also interested in adjacent fields such as generative AI and optimisation. I am currently working on disentangled representation learning. 
              </p> -->
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  
          <!-- ################### BID ###################### -->
          <tr>
            <!-- <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/BBS_fig1.png' width="160">
            </td> -->
            <td style="padding:20px;width:25%;vertical-align:middle">
              <video width="160" autoplay loop muted playsinline>
                <source src="images/BID.mp4" type="video/mp4">
              </video>
            </td>
          </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle> Bidirectional Decoding: Improving Action Chunking via Closed-Loop Resampling</papertitle>
              <br>
              Yuejiang Liu*, 
              <strong>Jubayer Ibn Hamid*</strong>,
              Annie Xie,
              Yoonho Lee,
              Max Du,
              Chelsea Finn
              <br>
              <p>
                (under review).
              </p>
              <p>
                <a href="https://arxiv.org/abs/2408.17355">Paper</a> &nbsp/&nbsp
                <a href="https://bid-robot.github.io/">Website</a> &nbsp/&nbsp
                <a href="https://github.com/Jubayer-Hamid/bid_lerobot">Code</a> &nbsp/&nbsp
                <a href="BID_blog.html">Blog</a>
              </p>
              <!-- <p>
                We propose Bidirectional Decoding (BID), a test-time decoding algorithm that enhances temporal consistency over extended sequences while enabling adaptive replanning in stochastic
                environments. Our theoretical results analyze under what circumstances action chunking reduces divergence between a learning agent and an expert demonstrator. 
              </p> -->
            </td>
          </tr>	 
          
          <!-- ########################### Offline evaluation ########################################### -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/offlinexonlinevalidation.png' width="160">
            </td>
          </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle> Offline Evaluation of Robotic Manipulation Policies </papertitle>
              <br>
              <strong>Jubayer Ibn Hamid</strong>,
              Micha≈Ç Zawalski,
              Yuejiang Liu, 
              Yoonho Lee,
              Karl Pertsch,
              Sergey Levine, 
              Chelsea Finn.
              <br>
              <p>
                (In preparation).
              </p>
            </td>
          </tr>	          
          <!-- ################### Tripod ###################### -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/Tripod_fig1.png' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> Tripod: Three Complementary Inductive Biases for Disentangled Representation Learning</papertitle>
              <br>
              Kyle Hsu*, 
              <strong>Jubayer Ibn Hamid*</strong>,
              Kaylee Burns,
              Chelsea Finn,
              Jiajun Wu 
              <br>
              <p>
                ICML, 2024.
              </p>
              <p>
                <a href="https://arxiv.org/abs/2404.10282">Paper</a> &nbsp/&nbsp
                <a href="https://github.com/kylehkhsu/tripod">Code</a>
              </p>
              <!-- <p>
                We endow autoencoders with three inductive biases for disentanglement - latent quantization, latent multiinformation regularization (using kernel density approximation), and
                a scale-invariant, normalized Hessian (off-diagonal) penalty. Our resulting model achieves state-of-the-art results on disentanglement benchmarks. 
              </p> -->
            </td>
          </tr>	

          <!-- ############### Pre-trained Visual Representations ############### -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/segmenting_features.png' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>What Makes Pre-trained Visual Representations Successful For Robust Manipulation?</papertitle>
              <br>
              Kaylee Burns,
              Zach Witzel, 
              <strong>Jubayer Ibn Hamid</strong>,
              Tianhe Yu, 
              Chelsea Finn, 
              Karol Hausman
              <br>
              <p>
                CoRL, 2024.
              </p>
              <p>
                <a href="https://arxiv.org/abs/2312.12444">Paper</a> &nbsp/&nbsp
                <a href="https://kayburns.github.io/segmentingfeatures/">Website</a>
              <br>
              <!-- <p>
                We find that visual representations designed for manipulation and control tasks do not necessarily generalize under subtle changes in lighting and scene texture or the introduction of distractor objects. Instead, emergent segmentation ability is a strong predictor of out-of-distribution generalization among ViT models. This metric is more predictive than others such as downstream ImageNet accuracy, in-domain accuracy, or shape-bias.
              </p> -->
            </td>
          </tr>		
				

        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading style="display:block; font-size:2em; margin-bottom: 10px;">Notes</heading>
              <p>
                I am sharing notes on various topics that have fascinated me. These are not meant to be in-depth. Rather, they are meant to cover some of the basic constructions that show up periodically and are also interesting in and of themselves.
              </p>
              <p>
                <a href="data/Algebraic topology notes.pdf">Algebraic Topology</a>. <i>Foundational constructions - fundamental group, homology and cohomology. (Incomplete and will typeset later). </i>&nbsp;&nbsp; 
              </p>
              <p>
                <a href="data/Algebraic_Geometry_Notes.pdf">Algebraic Geometry</a>. <i>Foundational constructions and results in algebraic geometry. </i>&nbsp;&nbsp; 
              </p>
              <p>
                <a href="data/Whitney_s_Theorems.pdf">Whitney's Embedding Theorem and Immersion Theorem</a>. <i>Weak versions of Whitney's Embedding and Immersion theorem, which are often sufficient. </i>&nbsp;&nbsp; 
              </p>
              <p>
                <a href="data/Policy_Gradient_Methods.pdf">Policy Gradient Methods</a>. <i>Building blocks (including the policy gradient theorems for both episodic and continuing tasks) of policy gradient algorithms.</i>&nbsp;&nbsp; 
              </p>
            </td>
          </tr>
        </tbody></table>	




        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;">
                <a href="https://jonbarron.info/">Template</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>
</html>